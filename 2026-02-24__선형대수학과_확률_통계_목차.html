# 과목 1: 머신러닝을 위한 선형대수학

---

## 1부. 벡터와 벡터 공간

### 1장. 벡터의 기초

#### 1.1 스칼라, 벡터, 행렬, 텐서의 정의와 표기법 (활용: 데이터 표현의 기본 단위 — 스칼라=손실값, 벡터=특성, 행렬=가중치, 텐서=미니배치)
#### 1.2 벡터의 기하학적 해석: 화살표와 좌표 (활용: 임베딩 공간에서의 데이터 시각화)
#### 1.3 벡터 덧셈과 스칼라 곱 (활용: 가중합 연산, 경사하강법의 파라미터 업데이트)
#### 1.4 선형결합과 생성 공간(Span) (활용: 특성 공간의 표현력 이해)
#### 1.5 선형독립과 선형종속 (활용: 다중공선성 진단, 중복 특성 제거)

### 2장. 벡터 공간과 부분공간

#### 2.1 벡터 공간의 정의와 공리 (활용: ML에서 다루는 공간의 수학적 기반)
#### 2.2 부분공간: 열공간, 영공간, 행공간 (활용: 선형 모델의 해 공간 구조 이해)
#### 2.3 기저와 차원 (활용: 데이터의 본질적 자유도, 차원 축소의 이론적 근거)
#### 2.4 좌표계와 기저 변환 (활용: 특성 변환, PCA에서의 좌표 재표현)
#### 2.5 랭크의 정의와 의미 (활용: 행렬의 정보량 판단, 저랭크 근사)

### 3장. 내적과 노름

#### 3.1 내적의 정의와 성질 (활용: 유사도 측정, 어텐션 스코어 계산)
#### 3.2 벡터의 노름: L1, L2, Lp, L∞ (활용: 정규화 — L1=Lasso, L2=Ridge, 드롭아웃 분석)
#### 3.3 코사인 유사도와 각도 해석 (활용: 추천 시스템, 문서 유사도, 임베딩 비교)
#### 3.4 직교성과 직교 보충 공간 (활용: Gram-Schmidt 과정, 직교 초기화)
#### 3.5 사영(Projection): 벡터를 부분공간에 투영 (활용: 최소제곱법의 기하학적 의미, PCA)

---

## 2부. 행렬과 선형 변환

### 4장. 행렬 연산의 기초

#### 4.1 행렬의 덧셈, 스칼라 곱, 전치 (활용: 배치 데이터 조작, 대칭 행렬 구성)
#### 4.2 행렬 곱셈과 그 해석: 행 관점, 열 관점, 외적 관점 (활용: 신경망의 순전파 연산)
#### 4.3 원소별 연산(Hadamard 곱)과 브로드캐스팅 (활용: 게이팅 메커니즘 — LSTM, 어텐션 마스킹)
#### 4.4 블록 행렬과 구조화된 행렬 (활용: 대규모 모델의 효율적 연산 설계)
#### 4.5 특수 행렬: 단위행렬, 대각행렬, 삼각행렬, 대칭행렬 (활용: 가중치 초기화, 공분산 행렬)

### 5장. 선형 변환으로서의 행렬

#### 5.1 선형 변환의 정의와 행렬 표현 (활용: 신경망의 각 층을 변환으로 이해)
#### 5.2 변환의 기하학적 해석: 회전, 스케일링, 전단, 사영 (활용: 데이터 변환 시각화, 특성 공간 변형 이해)
#### 5.3 합성 변환과 행렬 곱의 관계 (활용: 다층 신경망 = 변환의 합성)
#### 5.4 가역 변환과 역행렬 (활용: 정규방정식 풀이, Normalizing Flows)
#### 5.5 변환의 상과 핵 (활용: 모델의 표현력과 정보 손실 분석)

### 6장. 연립방정식과 행렬 분해 기초

#### 6.1 연립선형방정식의 행렬 표현 (활용: 선형 회귀를 행렬 방정식으로 정식화)
#### 6.2 가우스 소거법과 행 사다리꼴 (활용: 수치적 해법의 기초)
#### 6.3 LU 분해 (활용: 효율적인 연립방정식 풀이, 수치 안정성)
#### 6.4 역행렬의 계산과 존재 조건 (활용: 정규방정식의 유일해 존재 판별)
#### 6.5 행렬식(Determinant)의 정의와 기하학적 의미 (활용: 부피 변화 해석, 가우시안 분포의 정규화 상수)

---

## 3부. 고유값 분해와 스펙트럼 이론

### 7장. 고유값과 고유벡터

#### 7.1 고유값 문제의 정의: Av = λv (활용: 공분산 행렬의 주성분 방향 찾기)
#### 7.2 특성 방정식과 고유값 계산 (활용: 스펙트럼 분석의 수학적 기초)
#### 7.3 고유공간과 기하학적 의미 (활용: 데이터의 주요 변동 방향 해석)
#### 7.4 대각화: 조건과 절차 (활용: 행렬 거듭제곱의 효율적 계산, RNN 안정성 분석)
#### 7.5 대칭 행렬의 스펙트럼 정리 (활용: 공분산 행렬은 항상 직교 대각화 가능 — PCA의 이론적 보장)

### 8장. 특이값 분해(SVD)

#### 8.1 SVD의 정의: A = UΣV^T (활용: 차원 축소, 잠재 의미 분석, 추천 시스템)
#### 8.2 SVD의 기하학적 해석: 회전-스케일링-회전 (활용: 신경망 가중치의 변환 구조 이해)
#### 8.3 절단된 SVD(Truncated SVD)와 저랭크 근사 (활용: 행렬 압축, LoRA 기법의 이론적 기반)
#### 8.4 Eckart-Young 정리: 최적 저랭크 근사 (활용: 정보 손실 최소화의 수학적 보장)
#### 8.5 의사역행렬(Pseudoinverse)과 최소노름 해 (활용: 과결정/부족결정 시스템의 최소제곱 해)
#### 8.6 SVD와 PCA의 관계 (활용: 데이터 행렬로부터 직접 주성분 계산)

---

## 4부. 행렬 미적분과 최적화

### 9장. 다변수 미분의 행렬 표현

#### 9.1 편미분 복습과 그래디언트 벡터 (활용: 손실 함수의 파라미터별 변화율)
#### 9.2 야코비 행렬(Jacobian) (활용: 다중 출력 함수의 미분, 역전파에서의 체인 룰)
#### 9.3 헤시안 행렬(Hessian) (활용: 손실 곡면의 곡률 분석, 뉴턴법 최적화)
#### 9.4 행렬 미분: 스칼라-벡터, 벡터-벡터, 스칼라-행렬 (활용: 가중치 행렬에 대한 손실 함수 미분)
#### 9.5 체인 룰의 행렬 형태 (활용: 역전파 알고리즘의 수학적 유도)
#### 9.6 자주 쓰이는 행렬 미분 공식 모음 (활용: ∂(x^TAx)/∂x = 2Ax 등, 모델 유도 시 즉시 활용)

### 10장. 최적화의 선형대수학적 기초

#### 10.1 이차형식과 양정치/반양정치 행렬 (활용: 볼록 손실 함수의 판별, 커널 행렬의 유효성)
#### 10.2 최소제곱법의 정규방정식 유도 (활용: 선형 회귀의 닫힌 해 — β = (X^TX)^{-1}X^Ty)
#### 10.3 경사하강법과 그래디언트의 기하학 (활용: SGD, 미니배치 GD의 수학적 기초)
#### 10.4 조건수(Condition Number)와 수치 안정성 (활용: 학습 속도 선택, 특성 스케일링의 필요성)
#### 10.5 전처리: 센터링, 스케일링, 화이트닝 (활용: 배치 정규화의 선형대수학적 해석)

---

## 5부. 고급 주제: 딥러닝을 위한 선형대수학

### 11장. 텐서와 다차원 배열 연산

#### 11.1 텐서의 정의와 차수(order) (활용: CNN 입력(배치×채널×높이×너비), 어텐션 텐서)
#### 11.2 텐서 곱과 크로네커 곱 (활용: 다중 헤드 어텐션, 텐서 분해)
#### 11.3 텐서 축약(Contraction)과 아인슈타인 표기법 (활용: einsum을 이용한 효율적 텐서 연산 구현)
#### 11.4 텐서 분해: CP 분해, Tucker 분해 (활용: 모델 압축, 효율적 추론)

### 12장. 딥러닝 구조의 선형대수학

#### 12.1 완전연결층의 행렬 표현과 역전파 (활용: Dense/Linear 층의 순전파·역전파 유도)
#### 12.2 합성곱의 행렬 표현: Toeplitz 행렬과 im2col (활용: CNN 연산을 행렬 곱으로 변환)
#### 12.3 어텐션 메커니즘의 선형대수학: QK^T/√d (활용: Transformer의 Self-Attention 유도)
#### 12.4 정규화 기법의 선형대수학: 배치/레이어/그룹 정규화 (활용: 학습 안정화의 수학적 메커니즘)
#### 12.5 가중치 초기화와 스펙트럼 분석 (활용: Xavier/He 초기화의 분산 전파 분석)
#### 12.6 저랭크 적응(LoRA)과 행렬 근사 (활용: 대규모 모델의 효율적 파인튜닝)

### 13장. 수치선형대수학 실전

#### 13.1 부동소수점 산술과 수치 오차 (활용: 그래디언트 소실/폭발의 수치적 원인)
#### 13.2 희소 행렬과 효율적 저장·연산 (활용: 대규모 추천 시스템, 그래프 신경망의 인접 행렬)
#### 13.3 근사 행렬 연산: 무작위 사영, 스케치 (활용: 대규모 데이터의 근사 SVD, 차원 축소)
#### 13.4 자동 미분(Autograd)의 선형대수학적 구조 (활용: PyTorch/JAX의 역전파 엔진 내부 원리)
#### 13.5 GPU 연산과 행렬 곱 최적화 (활용: 배치 처리, 혼합 정밀도 학습의 수학적 기반)

---

---

# 과목 2: 머신러닝을 위한 확률 및 통계

---