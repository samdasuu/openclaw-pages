<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>사기 탐지 XGBoost 프로젝트 — 시작 전에 필요한 베이스 지식 정리</title>
  <meta name="description" content="사기 거래 탐지(Fraud Detection)에서 XGBoost를 단순 사용이 아니라 원리 이해→실험 설계→성능 개선으로 연결하기 위해 필요한 핵심 베이스 지식을 한 페이지로 정리." />
  <style>
    :root{
      --bg:#f8fafc;           /* slate-50 */
      --card:#ffffff;
      --text:#1f2937;         /* slate-800 */
      --muted:#64748b;        /* slate-500 */
      --border:#e2e8f0;       /* slate-200 */
      --accent:#2563eb;       /* blue-600 */
      --accent-weak:#dbeafe;  /* blue-100 */
      --codebg:#0b1220;
      --codefg:#e5e7eb;
    }
    html,body{margin:0;padding:0;background:var(--bg);color:var(--text);font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Helvetica,Arial,"Apple SD Gothic Neo","Noto Sans KR","Malgun Gothic",sans-serif;line-height:1.6;}
    a{color:var(--accent);text-decoration:none;}
    a:hover{text-decoration:underline;}
    .wrap{max-width:900px;margin:32px auto;padding:0 16px;}
    .card{background:var(--card);border:1px solid var(--border);border-radius:14px;box-shadow:0 1px 2px rgba(15,23,42,0.05);}
    header{padding:18px 22px 8px 22px;}
    .topline{display:flex;gap:12px;align-items:center;justify-content:space-between;flex-wrap:wrap;}
    .back{font-size:14px;color:var(--muted);}
    h1{font-size:24px;margin:10px 0 6px 0;}
    .meta{display:flex;gap:10px;flex-wrap:wrap;align-items:center;color:var(--muted);font-size:13px;margin-top:6px;}
    .tag{display:inline-block;padding:2px 8px;border-radius:999px;background:var(--accent-weak);color:#1d4ed8;font-weight:600;}

    .summary{margin:0 22px 18px 22px;padding:14px 14px;border:1px solid #bfdbfe;background:#eff6ff;border-radius:12px;}
    .summary b{display:block;margin-bottom:4px;}
    .content{padding:0 22px 22px 22px;}
    h2{font-size:18px;margin:26px 0 10px 0;padding-top:18px;border-top:1px solid var(--border);} 
    h3{font-size:15px;margin:16px 0 6px 0;}
    ul{margin:8px 0 8px 22px;}
    li{margin:4px 0;}
    .callout{border:1px solid var(--border);border-radius:12px;padding:12px 12px;background:#fcfcfd;}
    .codebox{margin-top:14px;border:1px solid var(--border);border-radius:12px;overflow:hidden;}
    .codebox .title{padding:10px 12px;background:#f1f5f9;color:#0f172a;font-weight:700;font-size:13px;border-bottom:1px solid var(--border);}
    pre{margin:0;padding:12px;background:var(--codebg);color:var(--codefg);overflow:auto;font-size:12.5px;line-height:1.5;}
    footer{padding:14px 22px;color:var(--muted);font-size:12.5px;border-top:1px solid var(--border);}
    .sep{height:10px;}
  </style>
</head>
<body>
  <div class="wrap">
    <div class="card">
      <header>
        <div class="topline">
          <div class="back"><a href="index.html">← Back</a></div>
          <div class="back">문서 · ML</div>
        </div>
        <h1>사기 탐지 XGBoost 프로젝트 — 시작 전에 필요한 베이스 지식</h1>
        <div class="meta">
          <span>date: 2026-02-16</span>
          <span class="tag">XGBoost</span>
          <span class="tag">Fraud Detection</span>
          <span class="tag">PR-AUC</span>
          <span class="tag">Calibration</span>
          <span class="tag">Leakage</span>
        </div>
      </header>

      <div class="summary">
        <b>요약 (3줄)</b>
        <div>이 프로젝트에서 “XGBoost를 썼다”가 아니라 <b>원리 이해 → 실험 설계 → 성능 개선</b>을 보여주려면,</div>
        <div><b>(1) 불균형/지표</b>, <b>(2) 누수 없는 검증</b>, <b>(3) 확률·임계값·비용</b>, <b>(4) 부스팅/정규화 하이퍼파라미터 해석</b>을 한 세트로 잡아야 한다.</div>
        <div>아래는 시작 전 최소 지식 + “이걸 알면 어떤 개선으로 이어지나”를 연결해서 정리했다.</div>
      </div>

      <div class="content">
        <h2>1) 문제 구조: 사기 탐지에서 “잘한다”의 의미</h2>
        <h3>왜 정확도(accuracy)가 무의미한가</h3>
        <ul>
          <li>사기 비율이 0.1%라면, 전부 정상이라고 찍어도 accuracy 99.9%다.</li>
          <li>따라서 목표는 <b>희귀 클래스 탐지 성능</b>과 <b>운영 의사결정 성능</b>으로 재정의해야 한다.</li>
        </ul>

        <h3>핵심 지표(반드시 이해)</h3>
        <ul>
          <li><b>Precision / Recall</b>: 사기라고 잡은 것 중 진짜(precision), 진짜 사기 중 잡은 비율(recall)</li>
          <li><b>PR-AUC</b>: 불균형에서 ROC-AUC보다 더 직접적으로 의미 있음</li>
          <li><b>Expected Cost</b>: FP/FN 비용을 두고, 임계값(threshold)을 비용 최소로 선택</li>
          <li><b>Calibration (Brier / Calibration curve)</b>: 확률이 “믿을만한지”. 운영에서는 매우 중요</li>
        </ul>

        <div class="callout">
          <b>개선으로 연결</b>
          <div>같은 모델이라도 <b>임계값을 비용 기준으로</b> 잡으면 “점수”가 아니라 <b>실제 손실(기대비용)</b>을 줄이는 방향으로 최적화할 수 있다.</div>
        </div>

        <h2>2) 데이터/검증: 누수(Leakage)와 올바른 Split</h2>
        <h3>누수의 대표 패턴</h3>
        <ul>
          <li><b>시간 누수</b>: 미래 정보가 과거 학습에 섞임(랜덤 split이 위험)</li>
          <li><b>엔티티 누수</b>: 같은 카드/유저/상점이 train/test에 동시에 존재(특히 집단 패턴이 강할 때)</li>
          <li><b>타깃 누수 피처</b>: 결과를 사실상 암시하는 피처(예: chargeback 이후 생성된 변수)</li>
        </ul>

        <h3>권장 검증 설계</h3>
        <ul>
          <li>가능하면 <b>시간 기준 holdout</b> (train=과거, test=미래)</li>
          <li>유저/카드 id가 있으면 <b>Group split</b> 고려(동일 엔티티 중복 방지)</li>
          <li>튜닝은 valid에서, 최종 보고는 test에서 <b>딱 한 번</b></li>
        </ul>

        <div class="callout">
          <b>개선으로 연결</b>
          <div>누수를 막으면 public score는 낮아질 수 있어도, “실무에서 터지는 모델”을 만들 확률이 줄고, 보고서 설득력이 급상승한다.</div>
        </div>

        <h2>3) XGBoost 핵심 원리: 부스팅(Boosting)과 목적함수</h2>
        <h3>Gradient Boosting 직관</h3>
        <ul>
          <li>모델은 여러 개의 작은 트리를 더해서 만든다: <code>F(x) = Σ f_k(x)</code></li>
          <li>각 단계에서 “현재 모델이 못 맞춘 부분(잔차)”을 <b>경사(gradient)</b> 방향으로 보정하는 트리를 추가한다.</li>
        </ul>

        <h3>왜 XGBoost가 강한가(포인트)</h3>
        <ul>
          <li><b>2차 근사</b>(Hessian) 기반 최적화로 안정적/빠른 수렴</li>
          <li>트리의 복잡도에 대한 <b>정규화(regularization)</b>가 목적함수에 내장</li>
          <li><b>결측치 방향 학습</b>: missing을 단순 대체하지 않아도 split에서 최적 방향을 학습</li>
        </ul>

        <div class="callout">
          <b>개선으로 연결</b>
          <div>“학습률/트리 수”, “깊이/분기 억제”, “샘플링/정규화”가 각각 <b>과적합을 어떤 메커니즘으로</b> 줄이는지 설명하고 실험하면, 튜닝이 ‘감’이 아니라 ‘논리’가 된다.</div>
        </div>

        <h2>4) 하이퍼파라미터: 무엇이 무엇을 제어하는가</h2>
        <h3>가장 중요(우선순위 높은 것들)</h3>
        <ul>
          <li><b>eta (learning_rate)</b> &amp; <b>n_estimators</b>: 한 번에 얼마나 고칠지 vs 몇 번 고칠지 (trade-off)</li>
          <li><b>max_depth</b>: 트리의 표현력(복잡도). 깊으면 과적합 위험↑</li>
          <li><b>min_child_weight</b>: 잎 노드가 너무 작은 샘플로 만들어지는 것을 방지</li>
          <li><b>gamma</b>: 분기(split)로 얻는 이득이 충분할 때만 분기하도록 하는 페널티</li>
          <li><b>subsample</b>, <b>colsample_bytree</b>: 샘플/피처 부분 샘플링으로 분산↓</li>
        </ul>

        <h3>정규화(설명 가능하게 쓰면 깊이감 올라감)</h3>
        <ul>
          <li><b>reg_lambda(L2)</b>, <b>reg_alpha(L1)</b>: leaf weight 크기를 억제 → 과도한 보정 방지</li>
        </ul>

        <h3>불균형(사기 탐지에서 필수)</h3>
        <ul>
          <li><b>scale_pos_weight</b>: 양성(사기) 클래스의 손실을 키워 학습이 사기 쪽을 더 보게 함</li>
          <li>단, 이 값만으로 끝나지 않음: 최종 의사결정은 <b>threshold</b>가 좌우한다.</li>
        </ul>

        <h2>5) 임계값(Threshold)과 비용: “모델 점수”를 “의사결정”으로 바꾸기</h2>
        <h3>왜 threshold 튜닝이 핵심인가</h3>
        <ul>
          <li>모델은 확률(또는 점수)을 출력하지만, 실제는 “차단/통과” 같은 이산 의사결정을 한다.</li>
          <li>따라서 <b>비용(손실)</b>을 정의하고 threshold를 최적화해야 한다.</li>
        </ul>

        <div class="codebox">
          <div class="title">템플릿: expected cost 계산(개념)</div>
          <pre><code>cost = FN_cost * FN + FP_cost * FP
# threshold t를 0~1 스윕하여 cost(t)가 최소가 되는 t* 선택
# 이때 precision/recall도 함께 기록해서 trade-off를 설명</code></pre>
        </div>

        <h2>6) 확률 보정(Calibration): PR-AUC 다음 단계</h2>
        <h3>캘리브레이션이 필요한 이유</h3>
        <ul>
          <li>“0.9 확률”이라고 했을 때 실제로 90%가 맞아야 운영(리스크 관리/룰 결합)에 쓸 수 있다.</li>
          <li>랭킹(정렬) 성능이 좋아도 확률이 틀리면 비용 기반 의사결정이 흔들린다.</li>
        </ul>

        <h3>대표 방법</h3>
        <ul>
          <li><b>Platt scaling</b>(sigmoid): 간단/안정적</li>
          <li><b>Isotonic regression</b>: 비선형 보정(데이터 많을 때 유리, 과적합 주의)</li>
        </ul>

        <div class="callout">
          <b>개선으로 연결</b>
          <div>캘리브레이션 후 threshold를 다시 최적화하면, PR-AUC는 비슷해도 <b>Expected Cost가 감소</b>하는 케이스가 자주 나온다.</div>
        </div>

        <h2>7) 해석/오류 분석: “왜 틀렸는지”가 다음 성능 개선이다</h2>
        <h3>필수 분석</h3>
        <ul>
          <li>False Negative(사기 놓침)만 모아서 공통 패턴 찾기</li>
          <li>특정 피처 구간/결측 패턴에서 실패하는지 확인</li>
          <li>시간대/금액대/거래 형태(가능하면)별 성능 분해</li>
        </ul>

        <h3>설명 도구</h3>
        <ul>
          <li><b>SHAP</b>: 전역 중요도 + 개별 예측 설명(“이 거래가 왜 사기라고 떴나”)</li>
          <li>단, SHAP을 ‘그림 붙이기’로 끝내지 말고 <b>오류 패턴 → 전처리/피처 개선</b>으로 연결</li>
        </ul>

        <h2>8) 재현성 &amp; 실험 관리: 포트폴리오에서 차이 나는 부분</h2>
        <ul>
          <li>seed 고정, 환경(requirements) 고정</li>
          <li>실험 결과를 표로 누적(runs.csv): 파라미터/지표/threshold/cost/메모</li>
          <li>최종 결론은 test에 대해 1회만</li>
        </ul>

        <div class="codebox">
          <div class="title">runs.csv에 기록하면 좋은 컬럼 예시</div>
          <pre><code>run_id, split, model, params, pr_auc_valid, pr_auc_test, brier_valid, threshold*, fp, fn, expected_cost, notes</code></pre>
        </div>

        <h2>9) “시작 전 체크리스트”(최소)</h2>
        <ul>
          <li>[ ] PR-AUC, precision/recall, confusion matrix 이해</li>
          <li>[ ] 불균형에서 ROC-AUC의 한계 설명 가능</li>
          <li>[ ] 시간/그룹 기반 split과 누수 사례 2개 이상 설명 가능</li>
          <li>[ ] XGBoost의 boosting 개념(잔차/그래디언트) 설명 가능</li>
          <li>[ ] eta vs n_estimators, max_depth, subsample/colsample, reg_alpha/lambda 역할 설명 가능</li>
          <li>[ ] threshold를 비용 기준으로 최적화하는 이유/방법 설명 가능</li>
          <li>[ ] calibration의 의미와 Platt/Isotonic 차이 설명 가능</li>
          <li>[ ] 오류 분석을 통해 다음 실험 가설을 세울 수 있음</li>
        </ul>

        <h2>10) (선택) 추천 참고 자료(짧게)</h2>
        <ul>
          <li>XGBoost 공식 문서: 파라미터/목적함수/정규화 설명</li>
          <li>Scikit-learn: calibration(Platt/Isotonic), PR curve 문서</li>
          <li>“Data leakage” 관련 글(시간 누수/그룹 누수 사례)</li>
        </ul>

        <div class="sep"></div>

        <div class="callout">
          <b>이 문서의 사용법</b>
          <div>프로젝트 진행 중 막히면, “지표/검증/확률/파라미터/오류 분석” 중 어디가 약한지 체크하고, 그 약점을 다음 실험(가설)로 바로 연결하면 된다.</div>
        </div>
      </div>

      <footer>
        Project: Fraud Detection with XGBoost (analysis-only) · Repo: <a href="https://github.com/samdasuu/openclaw-pages">samdasuu/openclaw-pages</a>
      </footer>
    </div>
  </div>
</body>
</html>
